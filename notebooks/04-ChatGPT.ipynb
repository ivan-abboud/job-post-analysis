{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "OPENAI_API_KEY = os.getenv('OPENAI_API_KEY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"../data/data_v2.csv\")\n",
    "data.raw_text.fillna('' , inplace=True)\n",
    "data.ocr_res.fillna('',inplace=True)\n",
    "\n",
    "data['full_text'] = (data.raw_text + '\\n' + data.ocr_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "openai.api_key = OPENAI_API_KEY\n",
    "\n",
    "# Set up the model and prompt\n",
    "model_engine = \"text-davinci-003\"\n",
    "question = \"\"\"\n",
    "extract the following fields from the text: job title, company name, salary, location, job type, years of experience, and required skills as keywords, if no info were found set field to none:\n",
    "\"\"\"\n",
    "job_post = ''\n",
    "prompt = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "latest_idx = 285\n",
    "responses = np.empty(data.full_text.shape , dtype='O')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' #career #jobposting \\n#SeniorDeveloper #JuniorDeveloper #PHP #Laravel #SQL #UI #Javascript #HTML5 #CSS #Bootstrap #JQuery #React #Angular #CV #ProjectURL #SyrianProgramming'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in range(latest_idx,data.shape[0]):\n",
    "    job_post = data.full_text.values[i]\n",
    "    if job_post is np.nan:\n",
    "      responses[i] = ''\n",
    "      continue\n",
    "    if job_post == '':\n",
    "      responses[i] = ''\n",
    "      continue\n",
    "    try:\n",
    "      completion = openai.Completion.create(\n",
    "      engine=model_engine,\n",
    "      prompt=question + '\\n' + job_post + '\\n',\n",
    "      max_tokens=500,\n",
    "      n=1,\n",
    "      stop=None,\n",
    "      temperature=0)\n",
    "      responses[i] = completion.choices[0].text\n",
    "    except:\n",
    "      responses[i] = 'Exception'\n",
    "    \n",
    "\n",
    "    \n",
    "    latest_idx = i\n",
    "    print(i)\n",
    "    if i%100==0:\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "res1 = pd.read_csv(\"../data/responses.csv\")\n",
    "res2 = pd.read_csv(\"../data/responses3.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    285\n",
       "dtype: int64"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res1.notna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    607\n",
       "dtype: int64"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res2.notna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = res1[:285]\n",
    "res = pd.concat([res , res2[285:]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "res.columns = ['chatgpt_response']\n",
    "res.to_csv(\"../data/chatgpt_response.csv\" , index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"../data/data_v2.csv\")\n",
    "data.ocr_res.fillna('' , inplace=True)\n",
    "data.raw_text.fillna('' , inplace=True)\n",
    "data['full_text'] = data.raw_text + '\\n' + data.ocr_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv(\"../data/data_v3.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                 0\n",
       "date               0\n",
       "date_unixtime      0\n",
       "photo            184\n",
       "width            152\n",
       "height           152\n",
       "text             160\n",
       "text_entities      0\n",
       "raw_text           0\n",
       "type               0\n",
       "ocr_res            0\n",
       "full_text          0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13, 12)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.loc[data.text.isna() & data.photo.isna()].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Job Post: nan\n",
      "----------------------------------------\n",
      "ChatGPT res: \n",
      "Job Title: Software Engineer\n",
      "Company Name: ABC Corporation\n",
      "Salary: None\n",
      "Location: San Francisco, CA\n",
      "Job Type: Full-time\n",
      "Years of Experience: 5+\n",
      "Required Skills: Java, JavaScript, HTML, CSS\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "can only concatenate str (not \"float\") to str",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[30], line 7\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m-\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m40\u001b[39m)\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mChatGPT res: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mres\u001b[38;5;241m.\u001b[39miloc[rand]\u001b[38;5;241m.\u001b[39mdescription\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m----> 7\u001b[0m display(Image\u001b[38;5;241m.\u001b[39mopen(\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m../data/\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miloc\u001b[49m\u001b[43m[\u001b[49m\u001b[43mrand\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mphoto\u001b[49m))\n",
      "\u001b[1;31mTypeError\u001b[0m: can only concatenate str (not \"float\") to str"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "rand = np.random.randint(0,res.shape[0])\n",
    "print(f'Job Post: {data.iloc[rand].full_text}')\n",
    "print('-'*40)\n",
    "print(f'ChatGPT res: {res.iloc[rand].description}')\n",
    "display(Image.open(\"../data/\"+data.iloc[rand].photo))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                              2398\n",
       "date             2022-12-01 09:09:27\n",
       "date_unixtime             1669878567\n",
       "photo                            NaN\n",
       "width                         1269.0\n",
       "height                        1277.0\n",
       "text                             NaN\n",
       "text_entities                     []\n",
       "raw_text                            \n",
       "type                           empty\n",
       "ocr_res                             \n",
       "full_text                         \\n\n",
       "Name: 819, dtype: object"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.iloc[rand]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "160"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.raw_text.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "186"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.ocr_res.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15, 12)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.loc[(data.raw_text=='') & (data.ocr_res == '')].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      Job Title:#senior and a junior #developer\\n \\n...\n",
       "1      Job Title:#cashier\\nJob Type: #full_time\\n \\nش...\n",
       "2      Company: #National_Technology_Group #NTG)\\nJob...\n",
       "3      Job title: #Employees for Operations Departmen...\n",
       "4      https://www.facebook.com/384708578676644/posts...\n",
       "                             ...                        \n",
       "887    مرحباً جميعاً \\nبدء استقبال الطلبات لمنحة #الل...\n",
       "888    🔵Job Title: #React JS Developer\\nJob location:...\n",
       "889    \\nJolgi online Send CV to: ozahraldeen@gmail.c...\n",
       "890    🧩Company: #YouTube group \\nJob title: #YouTube...\n",
       "891    ورشة عمل مجانية في إنترنت الأشياء\\n\\nبالتعاون ...\n",
       "Length: 892, dtype: object"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(data.raw_text + '\\n' + data.ocr_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                                                            2471\n",
       "date                                           2022-12-28 13:29:21\n",
       "date_unixtime                                           1672226961\n",
       "photo                    photos/photo_1911@28-12-2022_13-29-21.jpg\n",
       "width                                                       1131.0\n",
       "height                                                      1172.0\n",
       "text                                                           NaN\n",
       "text_entities                                                   []\n",
       "raw_text                                                       NaN\n",
       "type                                                         empty\n",
       "ocr_res          Jolgi online Send CV to: ozahraldeen@gmail.com...\n",
       "full_text                                                      NaN\n",
       "Name: 889, dtype: object"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resolving exceptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "openai.api_key = OPENAI_API_KEY\n",
    "#openai.api_key = os.getenv('OPENAI_API_KEY')\n",
    "# Set up the model and prompt\n",
    "model_engine = \"text-davinci-003\"\n",
    "question = \"\"\"\n",
    "extract the following fields from the text: job title, company name, salary, location, job type, years of experience, and required skills as keywords, if no info were found set field to none:\n",
    "\"\"\"\n",
    "job_post = ''\n",
    "prompt = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exceptions = data.loc[job_description.isna().all(axis=1) & (data.full_text!='\\n')]\n",
    "responses = np.empty(exceptions.full_text.shape , dtype='O')\n",
    "latest_idx = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31\n",
      "32\n",
      "33\n"
     ]
    }
   ],
   "source": [
    "for i in range(latest_idx,exceptions.shape[0]):\n",
    "    job_post = exceptions.full_text.values[i]\n",
    "    if job_post is np.nan:\n",
    "      responses[i] = ''\n",
    "      continue\n",
    "    if job_post == '':\n",
    "      responses[i] = ''\n",
    "      continue\n",
    "   \n",
    "    completion = openai.Completion.create(\n",
    "    engine=model_engine,\n",
    "    prompt=question + '\\n' + job_post + '\\n',\n",
    "    max_tokens=55,\n",
    "    n=1,\n",
    "    stop=None,\n",
    "    temperature=0)\n",
    "    responses[i] = completion.choices[0].text\n",
    "    \n",
    "\n",
    "    \n",
    "    latest_idx = i\n",
    "    print(i)\n",
    "    if i%100==0:\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.loc[job_description.isna().all(axis=1) & (data.full_text!='\\n'), [\"description\"]] = responses"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extracting required skills\n",
    "the first time we extracted the required skills was not good enough"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "openai.api_key =OPENAI_API_KEY\n",
    "model_engine = \"text-davinci-003\"\n",
    "\n",
    "question = \"list the soft and hard skills in a single word of the following job post:\"\n",
    "job_post = ''\n",
    "prompt = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"../data/data_v5.4.csv\")\n",
    "responses = pd.read_csv(\"../data/incomplete_job_skills.csv\")\n",
    "responses = responses[\"0\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🕹Job Title: #Flutter Developer\n",
      "Job Type: #Full Time\n",
      "Job Location: #Remotely or in #Damascus, Al-Jeser Al-Abead\n",
      "\n",
      "We are hiring ( flutter developer )\n",
      "\n",
      "📌 at least 3 years XP on android or ios\n",
      "📌 at least 2 years XP on flutter\n",
      "📌 full time only\n",
      "📌 advanced level in English\n",
      "📌Salary will be determined after the interview up to: 2000,000 SYP\n",
      "مكان العمل: في الشركة دمشق الجسر الأبيض أو عن بعد\n",
      "📮Send CV to: \n",
      "Career.solutions.fast@gmail.com\n",
      "\n",
      "#تواصل #فرص #عمل #توظيف #شاغر\n",
      "#Tawasol #Tawasol_Job\n",
      "#Hiring  #job #developer\n",
      "#Tawasol #Tawasol_Job\n",
      "#jobseekers #jobseeker #interview #covid #recruiter #jobsearching #engineer #hiringnow\n",
      "Jploi TAWASOL job vacancy Flutter Developer 11:22 Tuesday,Sep17 Full Time Remotely/ at the company office in Damascus Salary Up to:2000,000SYP Send yourCV to: Career.solutions.fast@gmail.com 0992081792 Jnlgi Jialgi\n"
     ]
    }
   ],
   "source": [
    "print(data.full_text.values[26])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "latest_idx = 26"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\nSoft Skills: Communication, Interpersonal, English.\\nHard Skills: Flutter, Android, iOS, Engineering.'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "responses[26]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "RateLimitError",
     "evalue": "You exceeded your current quota, please check your plan and billing details.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRateLimitError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 10\u001b[0m\n\u001b[0;32m      7\u001b[0m   responses[i] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m      8\u001b[0m   \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[1;32m---> 10\u001b[0m completion \u001b[38;5;241m=\u001b[39m \u001b[43mopenai\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCompletion\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     11\u001b[0m \u001b[43m\u001b[49m\u001b[43mengine\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_engine\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     12\u001b[0m \u001b[43m\u001b[49m\u001b[43mprompt\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquestion\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mjob_post\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     13\u001b[0m \u001b[43m\u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m200\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     14\u001b[0m \u001b[43m\u001b[49m\u001b[43mn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     15\u001b[0m \u001b[43m\u001b[49m\u001b[43mstop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m     16\u001b[0m \u001b[43m\u001b[49m\u001b[43mtemperature\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     17\u001b[0m responses[i] \u001b[38;5;241m=\u001b[39m completion\u001b[38;5;241m.\u001b[39mchoices[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mtext\n\u001b[0;32m     21\u001b[0m latest_idx \u001b[38;5;241m=\u001b[39m i\n",
      "File \u001b[1;32mc:\\Users\\Ivan\\Desktop\\Codes\\telegram-channel\\.venv\\lib\\site-packages\\openai\\api_resources\\completion.py:25\u001b[0m, in \u001b[0;36mCompletion.create\u001b[1;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[0;32m     24\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 25\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39mcreate(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m     26\u001b[0m     \u001b[39mexcept\u001b[39;00m TryAgain \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     27\u001b[0m         \u001b[39mif\u001b[39;00m timeout \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m time\u001b[39m.\u001b[39mtime() \u001b[39m>\u001b[39m start \u001b[39m+\u001b[39m timeout:\n",
      "File \u001b[1;32mc:\\Users\\Ivan\\Desktop\\Codes\\telegram-channel\\.venv\\lib\\site-packages\\openai\\api_resources\\abstract\\engine_api_resource.py:153\u001b[0m, in \u001b[0;36mEngineAPIResource.create\u001b[1;34m(cls, api_key, api_base, api_type, request_id, api_version, organization, **params)\u001b[0m\n\u001b[0;32m    127\u001b[0m \u001b[39m@classmethod\u001b[39m\n\u001b[0;32m    128\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcreate\u001b[39m(\n\u001b[0;32m    129\u001b[0m     \u001b[39mcls\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    136\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mparams,\n\u001b[0;32m    137\u001b[0m ):\n\u001b[0;32m    138\u001b[0m     (\n\u001b[0;32m    139\u001b[0m         deployment_id,\n\u001b[0;32m    140\u001b[0m         engine,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    150\u001b[0m         api_key, api_base, api_type, api_version, organization, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mparams\n\u001b[0;32m    151\u001b[0m     )\n\u001b[1;32m--> 153\u001b[0m     response, _, api_key \u001b[39m=\u001b[39m requestor\u001b[39m.\u001b[39;49mrequest(\n\u001b[0;32m    154\u001b[0m         \u001b[39m\"\u001b[39;49m\u001b[39mpost\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m    155\u001b[0m         url,\n\u001b[0;32m    156\u001b[0m         params\u001b[39m=\u001b[39;49mparams,\n\u001b[0;32m    157\u001b[0m         headers\u001b[39m=\u001b[39;49mheaders,\n\u001b[0;32m    158\u001b[0m         stream\u001b[39m=\u001b[39;49mstream,\n\u001b[0;32m    159\u001b[0m         request_id\u001b[39m=\u001b[39;49mrequest_id,\n\u001b[0;32m    160\u001b[0m         request_timeout\u001b[39m=\u001b[39;49mrequest_timeout,\n\u001b[0;32m    161\u001b[0m     )\n\u001b[0;32m    163\u001b[0m     \u001b[39mif\u001b[39;00m stream:\n\u001b[0;32m    164\u001b[0m         \u001b[39m# must be an iterator\u001b[39;00m\n\u001b[0;32m    165\u001b[0m         \u001b[39massert\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(response, OpenAIResponse)\n",
      "File \u001b[1;32mc:\\Users\\Ivan\\Desktop\\Codes\\telegram-channel\\.venv\\lib\\site-packages\\openai\\api_requestor.py:226\u001b[0m, in \u001b[0;36mAPIRequestor.request\u001b[1;34m(self, method, url, params, headers, files, stream, request_id, request_timeout)\u001b[0m\n\u001b[0;32m    205\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mrequest\u001b[39m(\n\u001b[0;32m    206\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[0;32m    207\u001b[0m     method,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    214\u001b[0m     request_timeout: Optional[Union[\u001b[39mfloat\u001b[39m, Tuple[\u001b[39mfloat\u001b[39m, \u001b[39mfloat\u001b[39m]]] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[0;32m    215\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tuple[Union[OpenAIResponse, Iterator[OpenAIResponse]], \u001b[39mbool\u001b[39m, \u001b[39mstr\u001b[39m]:\n\u001b[0;32m    216\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrequest_raw(\n\u001b[0;32m    217\u001b[0m         method\u001b[39m.\u001b[39mlower(),\n\u001b[0;32m    218\u001b[0m         url,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    224\u001b[0m         request_timeout\u001b[39m=\u001b[39mrequest_timeout,\n\u001b[0;32m    225\u001b[0m     )\n\u001b[1;32m--> 226\u001b[0m     resp, got_stream \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_interpret_response(result, stream)\n\u001b[0;32m    227\u001b[0m     \u001b[39mreturn\u001b[39;00m resp, got_stream, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mapi_key\n",
      "File \u001b[1;32mc:\\Users\\Ivan\\Desktop\\Codes\\telegram-channel\\.venv\\lib\\site-packages\\openai\\api_requestor.py:599\u001b[0m, in \u001b[0;36mAPIRequestor._interpret_response\u001b[1;34m(self, result, stream)\u001b[0m\n\u001b[0;32m    591\u001b[0m     \u001b[39mreturn\u001b[39;00m (\n\u001b[0;32m    592\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_interpret_response_line(\n\u001b[0;32m    593\u001b[0m             line, result\u001b[39m.\u001b[39mstatus_code, result\u001b[39m.\u001b[39mheaders, stream\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m\n\u001b[0;32m    594\u001b[0m         )\n\u001b[0;32m    595\u001b[0m         \u001b[39mfor\u001b[39;00m line \u001b[39min\u001b[39;00m parse_stream(result\u001b[39m.\u001b[39miter_lines())\n\u001b[0;32m    596\u001b[0m     ), \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m    597\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    598\u001b[0m     \u001b[39mreturn\u001b[39;00m (\n\u001b[1;32m--> 599\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_interpret_response_line(\n\u001b[0;32m    600\u001b[0m             result\u001b[39m.\u001b[39;49mcontent, result\u001b[39m.\u001b[39;49mstatus_code, result\u001b[39m.\u001b[39;49mheaders, stream\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m\n\u001b[0;32m    601\u001b[0m         ),\n\u001b[0;32m    602\u001b[0m         \u001b[39mFalse\u001b[39;00m,\n\u001b[0;32m    603\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\Ivan\\Desktop\\Codes\\telegram-channel\\.venv\\lib\\site-packages\\openai\\api_requestor.py:655\u001b[0m, in \u001b[0;36mAPIRequestor._interpret_response_line\u001b[1;34m(self, rbody, rcode, rheaders, stream)\u001b[0m\n\u001b[0;32m    653\u001b[0m stream_error \u001b[39m=\u001b[39m stream \u001b[39mand\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39merror\u001b[39m\u001b[39m\"\u001b[39m \u001b[39min\u001b[39;00m resp\u001b[39m.\u001b[39mdata\n\u001b[0;32m    654\u001b[0m \u001b[39mif\u001b[39;00m stream_error \u001b[39mor\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39m200\u001b[39m \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m rcode \u001b[39m<\u001b[39m \u001b[39m300\u001b[39m:\n\u001b[1;32m--> 655\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandle_error_response(\n\u001b[0;32m    656\u001b[0m         rbody, rcode, resp\u001b[39m.\u001b[39mdata, rheaders, stream_error\u001b[39m=\u001b[39mstream_error\n\u001b[0;32m    657\u001b[0m     )\n\u001b[0;32m    658\u001b[0m \u001b[39mreturn\u001b[39;00m resp\n",
      "\u001b[1;31mRateLimitError\u001b[0m: You exceeded your current quota, please check your plan and billing details."
     ]
    }
   ],
   "source": [
    "for i in range(latest_idx,data.full_text.shape[0]):\n",
    "    job_post = data.full_text.values[i]\n",
    "    if job_post is np.nan:\n",
    "      responses[i] = ''\n",
    "      continue\n",
    "    if job_post == '':\n",
    "      responses[i] = ''\n",
    "      continue\n",
    "   \n",
    "    completion = openai.Completion.create(\n",
    "    engine=model_engine,\n",
    "    prompt=question + '\\n' + job_post,\n",
    "    max_tokens=200,\n",
    "    n=1,\n",
    "    stop=None,\n",
    "    temperature=0)\n",
    "    responses[i] = completion.choices[0].text\n",
    "    \n",
    "\n",
    "    \n",
    "    latest_idx = i\n",
    "    print(i)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('.venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "0f1b3ad10751f8a1907d8ad058bc41b16e54a41930ed7864c21be18142c16aeb"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
